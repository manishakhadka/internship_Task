{"cells":[{"cell_type":"markdown","metadata":{},"source":["To use the fine-tuned model locally, we have to first merge the adapter with the base model and then save the full model.We’ll first load the tokenizer and base model using the transformers library. Then, we’ll set up the chat format using the trl library. Finally, we’ll load and merge the adapter to the base model using the PEFT library.\n","\n","The merge_and_unload() function will help us merge the adapter weights with the base model and use it as a standalone model."]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-22T07:10:25.212828Z","iopub.status.busy":"2024-07-22T07:10:25.212138Z","iopub.status.idle":"2024-07-22T07:10:26.286423Z","shell.execute_reply":"2024-07-22T07:10:26.285331Z","shell.execute_reply.started":"2024-07-22T07:10:25.212771Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n","/kaggle/input/final/__results__.html\n","/kaggle/input/final/__notebook__.ipynb\n","/kaggle/input/final/__output__.json\n","/kaggle/input/final/custom.css\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/run-x0bpzd1w.wandb\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/logs/debug.log\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/logs/debug-internal.log\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/wandb-summary.json\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/conda-environment.yaml\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/config.yaml\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/output.log\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/requirements.txt\n","/kaggle/input/final/wandb/run-20240722_062831-x0bpzd1w/files/wandb-metadata.json\n","/kaggle/input/final/final_/adapter_model.safetensors\n","/kaggle/input/final/final_/adapter_config.json\n","/kaggle/input/final/final_/README.md\n","/kaggle/input/final/final_/checkpoint-500/adapter_model.safetensors\n","/kaggle/input/final/final_/checkpoint-500/trainer_state.json\n","/kaggle/input/final/final_/checkpoint-500/training_args.bin\n","/kaggle/input/final/final_/checkpoint-500/adapter_config.json\n","/kaggle/input/final/final_/checkpoint-500/README.md\n","/kaggle/input/final/final_/checkpoint-500/tokenizer.json\n","/kaggle/input/final/final_/checkpoint-500/tokenizer_config.json\n","/kaggle/input/final/final_/checkpoint-500/scheduler.pt\n","/kaggle/input/final/final_/checkpoint-500/special_tokens_map.json\n","/kaggle/input/final/final_/checkpoint-500/optimizer.pt\n","/kaggle/input/final/final_/checkpoint-500/rng_state.pth\n","/kaggle/input/final/final_/checkpoint-635/adapter_model.safetensors\n","/kaggle/input/final/final_/checkpoint-635/trainer_state.json\n","/kaggle/input/final/final_/checkpoint-635/training_args.bin\n","/kaggle/input/final/final_/checkpoint-635/adapter_config.json\n","/kaggle/input/final/final_/checkpoint-635/README.md\n","/kaggle/input/final/final_/checkpoint-635/tokenizer.json\n","/kaggle/input/final/final_/checkpoint-635/tokenizer_config.json\n","/kaggle/input/final/final_/checkpoint-635/scheduler.pt\n","/kaggle/input/final/final_/checkpoint-635/special_tokens_map.json\n","/kaggle/input/final/final_/checkpoint-635/optimizer.pt\n","/kaggle/input/final/final_/checkpoint-635/rng_state.pth\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:11:53.279239Z","iopub.status.busy":"2024-07-22T07:11:53.278722Z","iopub.status.idle":"2024-07-22T07:13:13.371636Z","shell.execute_reply":"2024-07-22T07:13:13.370397Z","shell.execute_reply.started":"2024-07-22T07:11:53.279210Z"},"trusted":true},"outputs":[],"source":["%%capture\n","%pip install -U bitsandbytes\n","%pip install -U transformers\n","%pip install -U accelerate\n","%pip install -U peft\n","%pip install -U trl"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:13:30.515117Z","iopub.status.busy":"2024-07-22T07:13:30.514725Z","iopub.status.idle":"2024-07-22T07:13:30.519777Z","shell.execute_reply":"2024-07-22T07:13:30.518777Z","shell.execute_reply.started":"2024-07-22T07:13:30.515085Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n","new_model = \"/kaggle/input/final/final_/checkpoint-635/\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:13:37.583272Z","iopub.status.busy":"2024-07-22T07:13:37.582948Z","iopub.status.idle":"2024-07-22T07:15:46.418385Z","shell.execute_reply":"2024-07-22T07:15:46.417584Z","shell.execute_reply.started":"2024-07-22T07:13:37.583249Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-22 07:13:44.885644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-22 07:13:44.885762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-22 07:13:45.047289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b1d02bc1a0644a194629a5b70195dac","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from peft import PeftModel\n","import torch\n","from trl import setup_chat_format\n","# Reload tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","\n","base_model_reload = AutoModelForCausalLM.from_pretrained(\n","        base_model,\n","        return_dict=True,\n","        low_cpu_mem_usage=True,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        trust_remote_code=True,\n",")\n","\n","base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n","\n","# Merge adapter with base model\n","model = PeftModel.from_pretrained(base_model_reload, new_model)\n","\n","model = model.merge_and_unload()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:18:44.270860Z","iopub.status.busy":"2024-07-22T07:18:44.269814Z","iopub.status.idle":"2024-07-22T07:19:41.149936Z","shell.execute_reply":"2024-07-22T07:19:41.148920Z","shell.execute_reply.started":"2024-07-22T07:18:44.270826Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('final__/tokenizer_config.json',\n"," 'final__/special_tokens_map.json',\n"," 'final__/tokenizer.json')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"final__\")\n","tokenizer.save_pretrained(\"final__\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:20:38.123464Z","iopub.status.busy":"2024-07-22T07:20:38.122854Z","iopub.status.idle":"2024-07-22T07:20:38.278367Z","shell.execute_reply":"2024-07-22T07:20:38.277483Z","shell.execute_reply.started":"2024-07-22T07:20:38.123433Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient()\n","\n","# hf_token = user_secrets.get_secret(\"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\")\n","login(token =\"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\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:24:03.432407Z","iopub.status.busy":"2024-07-22T07:24:03.432043Z","iopub.status.idle":"2024-07-22T07:28:19.715120Z","shell.execute_reply":"2024-07-22T07:28:19.714111Z","shell.execute_reply.started":"2024-07-22T07:24:03.432377Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fdb4ca649a4453ca3c04284679e7a74","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b1d54dc8e7e4c088529895dd31f1c22","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01e3b2ebd1ae4792857440fc32da93ec","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9f24a93489c4ea6b2140939d336740a","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"886703d4b56243fcb93de29a6e0531a4","version_major":2,"version_minor":0},"text/plain":["Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/manishaaaaa/final__/commit/1c1c71d4f625572cf90b34de6417d42252d0e46c', commit_message='Upload tokenizer', commit_description='', oid='1c1c71d4f625572cf90b34de6417d42252d0e46c', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub(\"final__\", use_temp_dir=False)\n","tokenizer.push_to_hub(\"final__\", use_temp_dir=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":188242707,"sourceType":"kernelVersion"},{"isSourceIdPinned":true,"modelInstanceId":28083,"sourceId":33551,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
