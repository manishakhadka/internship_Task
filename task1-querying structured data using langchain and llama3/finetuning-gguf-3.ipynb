{"cells":[{"cell_type":"markdown","metadata":{},"source":["We can’t use the safetensors files locally as most local AI chatbots don’t support them. Instead, we'll convert it into the llama.cpp GGUF file format."]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-15T00:29:06.194918Z","iopub.status.busy":"2024-07-15T00:29:06.194550Z","iopub.status.idle":"2024-07-15T00:29:07.442296Z","shell.execute_reply":"2024-07-15T00:29:07.441021Z","shell.execute_reply.started":"2024-07-15T00:29:06.194887Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/final-merging/__results__.html\n","/kaggle/input/final-merging/__notebook__.ipynb\n","/kaggle/input/final-merging/__output__.json\n","/kaggle/input/final-merging/custom.css\n","/kaggle/input/final-merging/final__/model.safetensors.index.json\n","/kaggle/input/final-merging/final__/model-00003-of-00004.safetensors\n","/kaggle/input/final-merging/final__/config.json\n","/kaggle/input/final-merging/final__/model-00001-of-00004.safetensors\n","/kaggle/input/final-merging/final__/tokenizer.json\n","/kaggle/input/final-merging/final__/tokenizer_config.json\n","/kaggle/input/final-merging/final__/model-00004-of-00004.safetensors\n","/kaggle/input/final-merging/final__/special_tokens_map.json\n","/kaggle/input/final-merging/final__/model-00002-of-00004.safetensors\n","/kaggle/input/final-merging/final__/generation_config.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n","/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n"]}],"source":["\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T00:33:01.097067Z","iopub.status.busy":"2024-07-15T00:33:01.096709Z","iopub.status.idle":"2024-07-15T00:40:30.204920Z","shell.execute_reply":"2024-07-15T00:40:30.203499Z","shell.execute_reply.started":"2024-07-15T00:33:01.097039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n","Cloning into 'llama.cpp'...\n","remote: Enumerating objects: 1027, done.\u001b[K\n","remote: Counting objects: 100% (1027/1027), done.\u001b[K\n","remote: Compressing objects: 100% (775/775), done.\u001b[K\n","remote: Total 1027 (delta 241), reused 660 (delta 205), pack-reused 0\u001b[K\n","Receiving objects: 100% (1027/1027), 17.58 MiB | 20.00 MiB/s, done.\n","Resolving deltas: 100% (241/241), done.\n","/kaggle/working/llama.cpp\n"]}],"source":["\n","%cd /kaggle/working\n","!git clone --depth=1 https://github.com/ggerganov/llama.cpp.git\n","%cd /kaggle/working/llama.cpp\n","!sed -i 's|MK_LDFLAGS   += -lcuda|MK_LDFLAGS   += -L/usr/local/nvidia/lib64 -lcuda|' Makefile\n","!LLAMA_CUDA=1 conda run -n base make -j > /dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-15T00:41:26.050917Z","iopub.status.busy":"2024-07-15T00:41:26.049680Z","iopub.status.idle":"2024-07-15T00:44:04.384718Z","shell.execute_reply":"2024-07-15T00:44:04.383449Z","shell.execute_reply.started":"2024-07-15T00:41:26.050865Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Writing: 100%|███████████████████████████| 16.1G/16.1G [02:26<00:00, 110Mbyte/s]\n"]}],"source":["!python convert_hf_to_gguf.py /kaggle/input/final-merging/final__/ \\\n","    --outfile /kaggle/working/final__gguf \\\n","    --outtype f16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
