{"cells":[{"cell_type":"markdown","metadata":{},"source":["Finetuning the llama-3 model using custom dataset.\n","dataset =https://huggingface.co/datasets/manishaaaaa/text-to-sql2\n","model=official llama3 model\n","model is loaded using 4-bit precision due to memory constraints.\n","In this file, the adapter model is created. well attach the adapter layer with a few parameters, making the entire process faster and more memory-efficient."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-22T06:19:03.656426Z","iopub.status.busy":"2024-07-22T06:19:03.656081Z","iopub.status.idle":"2024-07-22T06:19:04.027032Z","shell.execute_reply":"2024-07-22T06:19:04.026082Z","shell.execute_reply.started":"2024-07-22T06:19:03.656396Z"},"trusted":true},"outputs":[],"source":["\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:05:22.648226Z","iopub.status.busy":"2024-07-30T05:05:22.647772Z","iopub.status.idle":"2024-07-30T05:07:20.257594Z","shell.execute_reply":"2024-07-30T05:07:20.256315Z","shell.execute_reply.started":"2024-07-30T05:05:22.648184Z"},"trusted":true},"outputs":[],"source":["#importing necessary libraries\n","%%capture\n","%pip install -U transformers \n","%pip install -U datasets \n","%pip install -U accelerate \n","%pip install -U peft \n","%pip install -U trl \n","%pip install -U bitsandbytes \n","%pip install -U wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:20.260003Z","iopub.status.busy":"2024-07-30T05:07:20.259695Z","iopub.status.idle":"2024-07-30T05:07:38.377867Z","shell.execute_reply":"2024-07-30T05:07:38.376893Z","shell.execute_reply.started":"2024-07-30T05:07:20.259975Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-30 05:07:27.264482: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-30 05:07:27.264599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-30 05:07:27.393119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["#essential python package import\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import (\n","    LoraConfig,\n","    PeftModel,\n","    prepare_model_for_kbit_training,\n","    get_peft_model,\n",")\n","import os, torch, wandb\n","from datasets import load_dataset\n","from trl import SFTTrainer, setup_chat_format"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.379523Z","iopub.status.busy":"2024-07-30T05:07:38.378972Z","iopub.status.idle":"2024-07-30T05:07:38.383467Z","shell.execute_reply":"2024-07-30T05:07:38.382481Z","shell.execute_reply.started":"2024-07-30T05:07:38.379498Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n","\n","new_model = \"final_\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.386308Z","iopub.status.busy":"2024-07-30T05:07:38.385853Z","iopub.status.idle":"2024-07-30T05:07:38.401311Z","shell.execute_reply":"2024-07-30T05:07:38.400489Z","shell.execute_reply.started":"2024-07-30T05:07:38.386278Z"},"trusted":true},"outputs":[],"source":["torch_dtype = torch.float16\n","attn_implementation = \"eager\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.402458Z","iopub.status.busy":"2024-07-30T05:07:38.402162Z","iopub.status.idle":"2024-07-30T05:09:31.124649Z","shell.execute_reply":"2024-07-30T05:09:31.123717Z","shell.execute_reply.started":"2024-07-30T05:07:38.402435Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"996ef41a922245528651a1e6f40532f5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# QLoRA config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch_dtype,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    attn_implementation=attn_implementation\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:31.126129Z","iopub.status.busy":"2024-07-30T05:09:31.125843Z","iopub.status.idle":"2024-07-30T05:09:31.636153Z","shell.execute_reply":"2024-07-30T05:09:31.635384Z","shell.execute_reply.started":"2024-07-30T05:09:31.126104Z"},"trusted":true},"outputs":[],"source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","model, tokenizer = setup_chat_format(model, tokenizer)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:31.637556Z","iopub.status.busy":"2024-07-30T05:09:31.637263Z","iopub.status.idle":"2024-07-30T05:09:32.990186Z","shell.execute_reply":"2024-07-30T05:09:32.989434Z","shell.execute_reply.started":"2024-07-30T05:09:31.637532Z"},"trusted":true},"outputs":[],"source":["# LoRA config\n","peft_config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",")\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:32.991790Z","iopub.status.busy":"2024-07-30T05:09:32.991501Z","iopub.status.idle":"2024-07-30T05:09:32.995760Z","shell.execute_reply":"2024-07-30T05:09:32.994882Z","shell.execute_reply.started":"2024-07-30T05:09:32.991765Z"},"trusted":true},"outputs":[],"source":["dataset_name = \"manishaaaaa/text-to-sql2\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:32.997365Z","iopub.status.busy":"2024-07-30T05:09:32.997087Z","iopub.status.idle":"2024-07-30T05:09:36.436666Z","shell.execute_reply":"2024-07-30T05:09:36.435626Z","shell.execute_reply.started":"2024-07-30T05:09:32.997342Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"686f6a0607884f18ad4585ceca0d19e8","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/303 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31a95d514c5b47d58efec91e3f429df0","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/22.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9d9daf3bea34decb85e1fe85e1aed23","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/284 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae0012b2561a428489f326bfd9aeb6d8","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/284 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"text/plain":["'<|im_start|>user\\nHere is a database schema: CREATE TABLE transactions (    `Account_No` VARCHAR(50) NOT NULL,    `Transaction_details` TEXT,    `Withdrawal_amount` INTEGER,    `Deposit_amount` INTEGER,    `Balance_amount` INTEGER,    `Value_date` DATE,    `Date` DATE) Please write me a SQL statement that answers the following question: How many transactions did I make in last 2 week<|im_end|>\\n<|im_start|>assistant\\nSELECT COUNT(*) AS Total_Transactions FROM transactions WHERE Value_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 2 WEEK)<|im_end|>\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#Importing the dataset\n","dataset = load_dataset(dataset_name, split=\"all\")\n","\n","\n","def format_chat_template(row):\n","    row_json = [{\"role\": \"user\", \"content\": row[\"user\"]},\n","               {\"role\": \"assistant\", \"content\": row[\"query\"]}]\n","    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n","    return row\n","\n","dataset = dataset.map(\n","    format_chat_template,\n","    num_proc=4,\n",")\n","\n","dataset['text'][3]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:36.439806Z","iopub.status.busy":"2024-07-30T05:09:36.439524Z","iopub.status.idle":"2024-07-30T05:09:36.458887Z","shell.execute_reply":"2024-07-30T05:09:36.457980Z","shell.execute_reply.started":"2024-07-30T05:09:36.439781Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:41.286254Z","iopub.status.busy":"2024-07-30T05:11:41.285577Z","iopub.status.idle":"2024-07-30T05:11:41.316493Z","shell.execute_reply":"2024-07-30T05:11:41.315549Z","shell.execute_reply.started":"2024-07-30T05:11:41.286200Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_arguments = TrainingArguments(\n","    output_dir=new_model,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=2,\n","    optim=\"paged_adamw_32bit\",\n","    num_train_epochs=5,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=0.2,\n","    logging_steps=1,\n","    warmup_steps=10,\n","    logging_strategy=\"steps\",\n","    learning_rate=2e-4,\n","    fp16=False,\n","    bf16=False,\n","    group_by_length=True,\n","    report_to=\"wandb\"\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:46.965517Z","iopub.status.busy":"2024-07-30T05:11:46.964571Z","iopub.status.idle":"2024-07-30T05:11:47.539758Z","shell.execute_reply":"2024-07-30T05:11:47.538923Z","shell.execute_reply.started":"2024-07-30T05:11:46.965481Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b25faf172db49b0b000a00285d320c3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/255 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    peft_config=peft_config,\n","    max_seq_length=512,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:51.388841Z","iopub.status.busy":"2024-07-30T05:11:51.387969Z","iopub.status.idle":"2024-07-30T05:38:22.600486Z","shell.execute_reply":"2024-07-30T05:38:22.599510Z","shell.execute_reply.started":"2024-07-30T05:11:51.388805Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240730_051228-3tqc36wl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/manishaa/huggingface/runs/3tqc36wl' target=\"_blank\">final_</a></strong> to <a href='https://wandb.ai/manishaa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/manishaa/huggingface' target=\"_blank\">https://wandb.ai/manishaa/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/manishaa/huggingface/runs/3tqc36wl' target=\"_blank\">https://wandb.ai/manishaa/huggingface/runs/3tqc36wl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='635' max='635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [635/635 25:33, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>127</td>\n","      <td>No log</td>\n","      <td>0.198811</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>No log</td>\n","      <td>0.171221</td>\n","    </tr>\n","    <tr>\n","      <td>381</td>\n","      <td>No log</td>\n","      <td>0.161364</td>\n","    </tr>\n","    <tr>\n","      <td>508</td>\n","      <td>No log</td>\n","      <td>0.151943</td>\n","    </tr>\n","    <tr>\n","      <td>635</td>\n","      <td>No log</td>\n","      <td>0.157865</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TrainOutput(global_step=635, training_loss=0.14665939451202634, metrics={'train_runtime': 1590.5501, 'train_samples_per_second': 0.802, 'train_steps_per_second': 0.399, 'total_flos': 8160090056466432.0, 'train_loss': 0.14665939451202634, 'epoch': 4.980392156862745})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:05:30.621716Z","iopub.status.busy":"2024-07-22T07:05:30.620965Z","iopub.status.idle":"2024-07-22T07:05:33.770123Z","shell.execute_reply":"2024-07-22T07:05:33.769259Z","shell.execute_reply.started":"2024-07-22T07:05:30.621685Z"},"trusted":true},"outputs":[],"source":["wandb.finish()\n","model.config.use_cache = True"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:38:57.907714Z","iopub.status.busy":"2024-07-30T05:38:57.906535Z","iopub.status.idle":"2024-07-30T05:39:06.228967Z","shell.execute_reply":"2024-07-30T05:39:06.228068Z","shell.execute_reply.started":"2024-07-30T05:38:57.907672Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Withdrawal_amount) AS Total_Expenses FROM transactions WHERE Value_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 8 MONTH) ORDER BY Value_date DESC LIMIT 1;\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": f\"Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL, \n","        f'`Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER,' \n","        `f'Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question: Total expenses/spendings of last 8 months ?\"\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:41:48.442354Z","iopub.status.busy":"2024-07-30T05:41:48.441712Z","iopub.status.idle":"2024-07-30T05:41:57.484546Z","shell.execute_reply":"2024-07-30T05:41:57.483675Z","shell.execute_reply.started":"2024-07-30T05:41:48.442323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Withdrawal_amount) AS Total_Spending FROM transactions WHERE YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE())\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL, `Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER, `Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question: Amount spent this year ??\"\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:43:46.865646Z","iopub.status.busy":"2024-07-30T05:43:46.864520Z","iopub.status.idle":"2024-07-30T05:43:54.750695Z","shell.execute_reply":"2024-07-30T05:43:54.749792Z","shell.execute_reply.started":"2024-07-30T05:43:46.865594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Deposit_amount) AS Total_Income FROM transactions WHERE YEAR(Value_date) = YEAR(CURRENT_DATE()) AND MONTH(Value_date) >= MONTH(CURRENT_DATE()) - 5 ORDER BY Value_date DESC LIMIT 5;\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": f'''Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL,\n","        `Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER,\n","        `Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question:\n","        What is my income of the last 5 months of this year?'''\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:45:21.341178Z","iopub.status.busy":"2024-07-30T05:45:21.340323Z","iopub.status.idle":"2024-07-30T05:45:27.145198Z","shell.execute_reply":"2024-07-30T05:45:27.144223Z","shell.execute_reply.started":"2024-07-30T05:45:21.341146Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]}],"source":["trainer.model.save_pretrained(new_model)\n","# trainer.model.push_to_hub(new_model, use_temp_dir=False,token=\"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"isSourceIdPinned":true,"modelId":39106,"modelInstanceId":28083,"sourceId":33551,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
