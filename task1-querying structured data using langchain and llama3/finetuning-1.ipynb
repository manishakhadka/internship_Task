{"cells":[{"cell_type":"markdown","metadata":{},"source":["Finetuning the llama-3 model using custom dataset.\n","dataset =https://huggingface.co/datasets/manishaaaaa/text-to-sql2\n","model=official llama3 model\n","model is loaded using 4-bit precision due to memory constraints.\n","In this file, the adapter model is created. weâ€™ll attach the adapter layer with a few parameters, making the entire process faster and more memory-efficient."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-22T06:19:03.656426Z","iopub.status.busy":"2024-07-22T06:19:03.656081Z","iopub.status.idle":"2024-07-22T06:19:04.027032Z","shell.execute_reply":"2024-07-22T06:19:04.026082Z","shell.execute_reply.started":"2024-07-22T06:19:03.656396Z"},"trusted":true},"outputs":[],"source":["\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:05:22.648226Z","iopub.status.busy":"2024-07-30T05:05:22.647772Z","iopub.status.idle":"2024-07-30T05:07:20.257594Z","shell.execute_reply":"2024-07-30T05:07:20.256315Z","shell.execute_reply.started":"2024-07-30T05:05:22.648184Z"},"trusted":true},"outputs":[],"source":["#importing necessary libraries\n","%%capture\n","%pip install -U transformers \n","%pip install -U datasets \n","%pip install -U accelerate \n","%pip install -U peft \n","%pip install -U trl \n","%pip install -U bitsandbytes \n","%pip install -U wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:20.260003Z","iopub.status.busy":"2024-07-30T05:07:20.259695Z","iopub.status.idle":"2024-07-30T05:07:38.377867Z","shell.execute_reply":"2024-07-30T05:07:38.376893Z","shell.execute_reply.started":"2024-07-30T05:07:20.259975Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-30 05:07:27.264482: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-30 05:07:27.264599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-30 05:07:27.393119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["#essential python package import\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import (\n","    LoraConfig,\n","    PeftModel,\n","    prepare_model_for_kbit_training,\n","    get_peft_model,\n",")\n","import os, torch, wandb\n","from datasets import load_dataset\n","from trl import SFTTrainer, setup_chat_format"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.379523Z","iopub.status.busy":"2024-07-30T05:07:38.378972Z","iopub.status.idle":"2024-07-30T05:07:38.383467Z","shell.execute_reply":"2024-07-30T05:07:38.382481Z","shell.execute_reply.started":"2024-07-30T05:07:38.379498Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n","\n","new_model = \"final_\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.386308Z","iopub.status.busy":"2024-07-30T05:07:38.385853Z","iopub.status.idle":"2024-07-30T05:07:38.401311Z","shell.execute_reply":"2024-07-30T05:07:38.400489Z","shell.execute_reply.started":"2024-07-30T05:07:38.386278Z"},"trusted":true},"outputs":[],"source":["torch_dtype = torch.float16\n","attn_implementation = \"eager\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:07:38.402458Z","iopub.status.busy":"2024-07-30T05:07:38.402162Z","iopub.status.idle":"2024-07-30T05:09:31.124649Z","shell.execute_reply":"2024-07-30T05:09:31.123717Z","shell.execute_reply.started":"2024-07-30T05:07:38.402435Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"996ef41a922245528651a1e6f40532f5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# QLoRA config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch_dtype,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    attn_implementation=attn_implementation\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:31.126129Z","iopub.status.busy":"2024-07-30T05:09:31.125843Z","iopub.status.idle":"2024-07-30T05:09:31.636153Z","shell.execute_reply":"2024-07-30T05:09:31.635384Z","shell.execute_reply.started":"2024-07-30T05:09:31.126104Z"},"trusted":true},"outputs":[],"source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","model, tokenizer = setup_chat_format(model, tokenizer)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:31.637556Z","iopub.status.busy":"2024-07-30T05:09:31.637263Z","iopub.status.idle":"2024-07-30T05:09:32.990186Z","shell.execute_reply":"2024-07-30T05:09:32.989434Z","shell.execute_reply.started":"2024-07-30T05:09:31.637532Z"},"trusted":true},"outputs":[],"source":["# LoRA config\n","peft_config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",")\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:32.991790Z","iopub.status.busy":"2024-07-30T05:09:32.991501Z","iopub.status.idle":"2024-07-30T05:09:32.995760Z","shell.execute_reply":"2024-07-30T05:09:32.994882Z","shell.execute_reply.started":"2024-07-30T05:09:32.991765Z"},"trusted":true},"outputs":[],"source":["dataset_name = \"manishaaaaa/text-to-sql2\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:32.997365Z","iopub.status.busy":"2024-07-30T05:09:32.997087Z","iopub.status.idle":"2024-07-30T05:09:36.436666Z","shell.execute_reply":"2024-07-30T05:09:36.435626Z","shell.execute_reply.started":"2024-07-30T05:09:32.997342Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"686f6a0607884f18ad4585ceca0d19e8","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/303 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31a95d514c5b47d58efec91e3f429df0","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/22.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9d9daf3bea34decb85e1fe85e1aed23","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/284 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae0012b2561a428489f326bfd9aeb6d8","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/284 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"text/plain":["'<|im_start|>user\\nHere is a database schema: CREATE TABLE transactions (    `Account_No` VARCHAR(50) NOT NULL,    `Transaction_details` TEXT,    `Withdrawal_amount` INTEGER,    `Deposit_amount` INTEGER,    `Balance_amount` INTEGER,    `Value_date` DATE,    `Date` DATE) Please write me a SQL statement that answers the following question: How many transactions did I make in last 2 week<|im_end|>\\n<|im_start|>assistant\\nSELECT COUNT(*) AS Total_Transactions FROM transactions WHERE Value_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 2 WEEK)<|im_end|>\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#Importing the dataset\n","dataset = load_dataset(dataset_name, split=\"all\")\n","\n","\n","def format_chat_template(row):\n","    row_json = [{\"role\": \"user\", \"content\": row[\"user\"]},\n","               {\"role\": \"assistant\", \"content\": row[\"query\"]}]\n","    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n","    return row\n","\n","dataset = dataset.map(\n","    format_chat_template,\n","    num_proc=4,\n",")\n","\n","dataset['text'][3]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:09:36.439806Z","iopub.status.busy":"2024-07-30T05:09:36.439524Z","iopub.status.idle":"2024-07-30T05:09:36.458887Z","shell.execute_reply":"2024-07-30T05:09:36.457980Z","shell.execute_reply.started":"2024-07-30T05:09:36.439781Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:41.286254Z","iopub.status.busy":"2024-07-30T05:11:41.285577Z","iopub.status.idle":"2024-07-30T05:11:41.316493Z","shell.execute_reply":"2024-07-30T05:11:41.315549Z","shell.execute_reply.started":"2024-07-30T05:11:41.286200Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_arguments = TrainingArguments(\n","    output_dir=new_model,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=2,\n","    optim=\"paged_adamw_32bit\",\n","    num_train_epochs=5,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=0.2,\n","    logging_steps=1,\n","    warmup_steps=10,\n","    logging_strategy=\"steps\",\n","    learning_rate=2e-4,\n","    fp16=False,\n","    bf16=False,\n","    group_by_length=True,\n","    report_to=\"wandb\"\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:46.965517Z","iopub.status.busy":"2024-07-30T05:11:46.964571Z","iopub.status.idle":"2024-07-30T05:11:47.539758Z","shell.execute_reply":"2024-07-30T05:11:47.538923Z","shell.execute_reply.started":"2024-07-30T05:11:46.965481Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b25faf172db49b0b000a00285d320c3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/255 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    peft_config=peft_config,\n","    max_seq_length=512,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:11:51.388841Z","iopub.status.busy":"2024-07-30T05:11:51.387969Z","iopub.status.idle":"2024-07-30T05:38:22.600486Z","shell.execute_reply":"2024-07-30T05:38:22.599510Z","shell.execute_reply.started":"2024-07-30T05:11:51.388805Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240730_051228-3tqc36wl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/manishaa/huggingface/runs/3tqc36wl' target=\"_blank\">final_</a></strong> to <a href='https://wandb.ai/manishaa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/manishaa/huggingface' target=\"_blank\">https://wandb.ai/manishaa/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/manishaa/huggingface/runs/3tqc36wl' target=\"_blank\">https://wandb.ai/manishaa/huggingface/runs/3tqc36wl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='635' max='635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [635/635 25:33, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>127</td>\n","      <td>No log</td>\n","      <td>0.198811</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>No log</td>\n","      <td>0.171221</td>\n","    </tr>\n","    <tr>\n","      <td>381</td>\n","      <td>No log</td>\n","      <td>0.161364</td>\n","    </tr>\n","    <tr>\n","      <td>508</td>\n","      <td>No log</td>\n","      <td>0.151943</td>\n","    </tr>\n","    <tr>\n","      <td>635</td>\n","      <td>No log</td>\n","      <td>0.157865</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TrainOutput(global_step=635, training_loss=0.14665939451202634, metrics={'train_runtime': 1590.5501, 'train_samples_per_second': 0.802, 'train_steps_per_second': 0.399, 'total_flos': 8160090056466432.0, 'train_loss': 0.14665939451202634, 'epoch': 4.980392156862745})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T07:05:30.621716Z","iopub.status.busy":"2024-07-22T07:05:30.620965Z","iopub.status.idle":"2024-07-22T07:05:33.770123Z","shell.execute_reply":"2024-07-22T07:05:33.769259Z","shell.execute_reply.started":"2024-07-22T07:05:30.621685Z"},"trusted":true},"outputs":[],"source":["wandb.finish()\n","model.config.use_cache = True"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:38:57.907714Z","iopub.status.busy":"2024-07-30T05:38:57.906535Z","iopub.status.idle":"2024-07-30T05:39:06.228967Z","shell.execute_reply":"2024-07-30T05:39:06.228068Z","shell.execute_reply.started":"2024-07-30T05:38:57.907672Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Withdrawal_amount) AS Total_Expenses FROM transactions WHERE Value_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 8 MONTH) ORDER BY Value_date DESC LIMIT 1;\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": f\"Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL, \n","        f'`Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER,' \n","        `f'Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question: Total expenses/spendings of last 8 months ?\"\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:41:48.442354Z","iopub.status.busy":"2024-07-30T05:41:48.441712Z","iopub.status.idle":"2024-07-30T05:41:57.484546Z","shell.execute_reply":"2024-07-30T05:41:57.483675Z","shell.execute_reply.started":"2024-07-30T05:41:48.442323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Withdrawal_amount) AS Total_Spending FROM transactions WHERE YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE()) AND YEAR(Value_date) = YEAR(CURRENT_DATE())\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL, `Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER, `Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question: Amount spent this year ??\"\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:43:46.865646Z","iopub.status.busy":"2024-07-30T05:43:46.864520Z","iopub.status.idle":"2024-07-30T05:43:54.750695Z","shell.execute_reply":"2024-07-30T05:43:54.749792Z","shell.execute_reply.started":"2024-07-30T05:43:46.865594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","SELECT SUM(Deposit_amount) AS Total_Income FROM transactions WHERE YEAR(Value_date) = YEAR(CURRENT_DATE()) AND MONTH(Value_date) >= MONTH(CURRENT_DATE()) - 5 ORDER BY Value_date DESC LIMIT 5;\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": f'''Here is a database schema: CREATE TABLE transactions ( `Account_No` VARCHAR(50) NOT NULL,\n","        `Transaction_details` TEXT, `Withdrawal_amount` INTEGER, `Deposit_amount` INTEGER, `Balance_amount` INTEGER,\n","        `Value_date` DATE, `Date` DATE) Please write me a SQL statement that answers the following question:\n","        What is my income of the last 5 months of this year?'''\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T05:45:21.341178Z","iopub.status.busy":"2024-07-30T05:45:21.340323Z","iopub.status.idle":"2024-07-30T05:45:27.145198Z","shell.execute_reply":"2024-07-30T05:45:27.144223Z","shell.execute_reply.started":"2024-07-30T05:45:21.341146Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]}],"source":["trainer.model.save_pretrained(new_model)\n","# trainer.model.push_to_hub(new_model, use_temp_dir=False,token=\"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"isSourceIdPinned":true,"modelId":39106,"modelInstanceId":28083,"sourceId":33551,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
